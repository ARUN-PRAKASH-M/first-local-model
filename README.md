# Building a RAG Application with Open-Source Models: Llama 3

This repository provides a comprehensive tutorial on how to build a Retrieval-Augmented Generation (RAG) application using open-source models, specifically Llama 3. The tutorial is implemented using Jupyter Notebook and includes examples with some Microsoft test documentation.

## Table of Contents
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Code Explanation](#code-explanation)
- [Contributing](#contributing)

## Introduction

RAG is a powerful approach that combines the strengths of retrieval-based and generation-based models. In this tutorial, you will learn how to:
- Load and preprocess documents.
- Use Llama 3 for both retrieval and generation tasks.
- Implement a complete RAG pipeline in a Jupyter Notebook environment.

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/TheCodeCraftsbeing/first-local-model.git
   ```
2. Navigate to the project directory:
   ```bash
   cd your-LOCALrepo-name
   ```
3. Install the required packages(added packages I remember but some pacckages may be missing):
   ```bash
   pip install -r requirements.txt
   ```

## Usage

1. Ensure you have your OpenAI API key available. You can set it in a `.env` file as follows so that you can verify you answer with llama3:
   ```
   OPENAI_API_KEY=your_openai_api_key
   ```
2. Open the Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
3. Run the cells in the notebook to see the RAG application in action.


## Contributing

Contributions are welcome! 
